<p align="center">
  <img src="logo_VietRXhelper.png" alt="VietRx Helper Logo" height="300">
</p>

# VietRx Helper: AI-Powered Medical Assistant for the Elderly

> **A safety-first, multimodal AI system designed to bridge the health literacy gap for Vietnamese immigrants using Computer Vision, RAG, and a Dual-LLM Audit Architecture.**

---

## ğŸ“– Overview

**VietRx Helper** is an intelligent assistive technology designed to help elderly Vietnamese individuals understand complex medication labels. Unlike standard translation tools, this system prioritizes **medical safety** and **cultural adaptation**.

The core innovation lies in its **Dual-LLM Safety Architecture**, where one AI generates empathetic advice while a second "Auditor" AI verifies the content against official FDA records to prevent hallucinations before the user hears a single word.

## ğŸš€ Key Features

* **ğŸ‘ï¸ End-to-End Computer Vision:**

  * Utilizes **YOLOv8 (Nano)** fine-tuned on a custom drug dataset to detect drug names on bottle labels.
  * Integrates **EasyOCR** with grayscale + threshold preprocessing for robust text extraction.

* **ğŸ›¡ï¸ Dual-LLM Safety Protocol (Reviewer-Refiner):**

  * **The Doctor (Generator):** Drafts culturally appropriate advice using polite Vietnamese honorifics.
  * **The Auditor (Evaluator):** Performs strict fact-checking using cross-referenced FDA data.

* **ğŸ“š RAG (Retrieval-Augmented Generation):**

  * Anchors generation to a verified local FDA Knowledge Base built from the OpenFDA API.

* **ğŸ§  Cultural Adaptation (Generative AI):**

  * Uses **Google Gemini 2.5 Flash** to translate pharmacological terminology into easy-to-understand Vietnamese.

* **ğŸ—£ï¸ Text-to-Speech (TTS):**

  * Outputs validated advice via natural Vietnamese speech.

## ğŸ—ï¸ System Architecture

1. **Data Acquisition Layer:** ETL script (`mining.py`) pulls and cleans NDC/FDA drug data.

2. **Vision Layer:**

   * Raw Image â†’ YOLOv8 Detection â†’ Cropping â†’ OCR.
   * Output: Drug name candidate.

3. **Knowledge Retrieval Layer:**

   * Fuzzy string matching â†’ Retrieve Ground Truth (ingredients, pharm class).

4. **Dual-LLM Reasoning Layer:**

   * **Doctor Agent:** draft response.
   * **Auditor Agent:** validates accuracy & forces regeneration if mismatched.

5. **Interaction Layer:**

   * Sanitizes text â†’ TTS audio output.

## ğŸ“‚ Project Structure

```text
VietRx-Project/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best.pt               
â”œâ”€â”€ src/                      
â”‚   â”œâ”€â”€ main.py               
â”‚   â”œâ”€â”€ vision.py
â”‚   â”œâ”€â”€ knowledge.py
â”‚   â””â”€â”€ brain.py              
â”œâ”€â”€ tests_webcam/             
â”‚   â”œâ”€â”€ main_test.py          
â”‚   â”œâ”€â”€ vision_test.py        
â”‚   â””â”€â”€ knowledge_test.py     
â”œâ”€â”€ fda_database.json         
â”œâ”€â”€ requirements.txt          
â”œâ”€â”€ .env
â””â”€â”€ README.md                 
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites

* Python 3.9+
* Google Gemini API Key

### 1. Clone the Repository

```bash
git clone https://github.com/phongilm20/VietRx-Helper.git
cd VietRx-Helper
```

### 2. Install Dependencies

```bash
pip install requests google-genai ultralytics easyocr opencv-python gTTS
```

### 3. Setup Environment

Replace the placeholder API Key in `brain.py` with your actual Google Gemini API Key.

### 4. Initialize Database

```bash
python mining.py
```

*(Generates ~5000 FDA-verified drug records.)*

## ğŸ’» Usage

1. Add an image of a medication bottle (e.g., `test.jpg`).
2. Run:

```bash
python main.py
```

3. Pipeline:

   * Detect drug name.
   * Retrieve FDA data.
   * Doctor AI drafts advice.
   * Auditor AI validates correctness.
   * Audio is generated and played.

## ğŸ”¬ Tech Stack

* **Language:** Python 3.10
* **Computer Vision:** YOLOv8, EasyOCR, OpenCV
* **Generative AI:** Google Gemini 2.5 Flash (Dual-Layer Architecture)
* **Database:** OpenFDA
* **Audio:** gTTS

## âš ï¸ Disclaimer

This is a research prototype for educational purposes and **not** a medical substitute.

## ğŸ‘¨â€ğŸ’» Author

**Nguyen Phong**

* Department of Computer Science & Engineering
* Wright State University
